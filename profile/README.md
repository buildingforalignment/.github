## Hi there 👋

Welcome to buildingforalignment.

buildingforalignment is a home for researching in philosophy and psychology using the help of computational sciences. Particular interests include the use of simulation methods, reinforcement learning
and large language models to better understand human nature and the nature of reality, as we experience it. This work takes the view that agent models may be useful models of human cognition. No claims 
are made about the potential equivalency of these models to human cognition. All models are analogies, use to study a subset of the qualities of a system. We believe there exist many useful computational models
which shall help us study human cognition and resulting philosophical implications.

Below is a list of experiments planned:
- [In progress] What does the distribution of lifetime rewards using the same starting model, tell us about agency?
- 
<!--

**Here are some ideas to get you started:**

🙋‍♀️ A short introduction - what is your organization all about?
🌈 Contribution guidelines - how can the community get involved?
👩‍💻 Useful resources - where can the community find your docs? Is there anything else the community should know?
🍿 Fun facts - what does your team eat for breakfast?
🧙 Remember, you can do mighty things with the power of [Markdown](https://docs.github.com/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
-->
